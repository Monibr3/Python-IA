





import numpy as np               
import pandas as pd             
import matplotlib.pyplot as plt  
import seaborn as sns     
import sys
import os    





from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier






ruta_datos = r"C:/Archivos_de_trabajos/Portafolio-IA-Python/02_Proyectos_datosclásicos/1-JupyterNotebook/2.1-Predicion_impago_creditos/default_credit_clients.csv"





ruta_datos = r"C:/Archivos_de_trabajos/Portafolio-IA-Python/02_Proyectos_datosclásicos/1-JupyterNotebook/2.1-Predicion_impago_creditos/default_credit_clients.csv"
try:
    # Comprobamos si el archivo existe
    if not os.path.exists(ruta_datos):
        raise FileNotFoundError(f"No se encontró el archivo: {ruta_datos}")

    # Leemos el CSV con separador ';' y codificación latin-1
    datos = pd.read_csv(ruta_datos, sep=";", encoding="latin-1", header=1)
    print("Archivo CSV leído correctamente.")

except FileNotFoundError as e:
    print("Error:", e)
    
except pd.errors.ParserError as e:
    print("Error al leer el CSV. Posiblemente está corrupto o mal formateado.")
    print(e)

except Exception as e:
    print("Ocurrió un error inesperado al leer el archivo CSV.")
    print(e)

# Eliminamos columna extra "Unnamed: 0" si existe
if "Unnamed: 0" in datos.columns:
    datos = datos.drop(columns=["Unnamed: 0"])

# Renombramos columnas a formato Python-friendly (minúsculas y sin espacios)
datos.columns = [col.lower().replace(" ", "_") for col in datos.columns]

# Visualizamos dimensiones y primeras filas
print("Dimensiones del dataset:", datos.shape)
display(datos.head())






# Visualizamos distribución de la variable objetivo
sns.countplot(x="default_payment_next_month", data=datos)
plt.title("Distribución de impagos")
plt.show()

# Estadísticas descriptivas de las variables
display(datos.describe())

# Comprobación de valores nulos
print("Valores nulos por columna:")
print(datos.isnull().sum())






# Separamos variables de entrenamiento (X) y variable objetivo (y)
X = datos.drop(["id", "default_payment_next_month"], axis=1)
y = datos["default_payment_next_month"]

# Dividimos en conjunto de entrenamiento (80%) y prueba (20%)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Escalamos las variables para mejorar el rendimiento de la regresión logística
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)






modelo = RandomForestClassifier(
    n_estimators=200,         # número de árboles
    max_depth=10,             # profundidad máxima de los árboles
    random_state=42,
    class_weight='balanced'   # balancea las clases automáticamente
)
modelo.fit(X_train_scaled, y_train)
print("Modelo Random Forest entrenado con éxito.")  






y_pred = modelo.predict(X_test_scaled)

print("Exactitud (accuracy):", accuracy_score(y_test, y_pred))
print("\nInforme de clasificación:\n", classification_report(y_test, y_pred))

# Matriz de confusión
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=[0,1], yticklabels=[0,1])
plt.xlabel("Predicción")
plt.ylabel("Real")
plt.title("Matriz de Confusión")
plt.show()







cliente = X_test.iloc[0:1]  # tomamos un ejemplo del conjunto de prueba
cliente_escalado = scaler.transform(cliente)
prediccion = modelo.predict(cliente_escalado)
print("Predicción del cliente:", "Impago" if prediccion[0]==1 else "No impago")



